{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5d5e77e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import datetime\n",
    "import imutils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e66b933b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [70]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[1;32m---> 71\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [70]\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     23\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m---> 24\u001b[0m     frame \u001b[38;5;241m=\u001b[39m \u001b[43mimutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m600\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     total_frames \u001b[38;5;241m=\u001b[39m total_frames \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     27\u001b[0m     (H, W) \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\imutils\\convenience.py:69\u001b[0m, in \u001b[0;36mresize\u001b[1;34m(image, width, height, inter)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresize\u001b[39m(image, width\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, height\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, inter\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mINTER_AREA):\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;66;03m# initialize the dimensions of the image to be resized and\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# grab the image size\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m     (h, w) \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[:\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# if both the width and height are None, then return the\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;66;03m# original image\u001b[39;00m\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m width \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m height \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "protopath = \"MobileNetSSD_deploy.prototxt\"\n",
    "modelpath = \"MobileNetSSD_deploy.caffemodel\"\n",
    "detector = cv2.dnn.readNetFromCaffe(prototxt=protopath, caffeModel=modelpath)\n",
    "# Only enable it if you are using OpenVino environment\n",
    "# detector.setPreferableBackend(cv2.dnn.DNN_BACKEND_INFERENCE_ENGINE)\n",
    "# detector.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
    "\n",
    "\n",
    "CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n",
    "           \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "           \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\",\n",
    "           \"sofa\", \"train\", \"tvmonitor\"]\n",
    "\n",
    "\n",
    "def main():\n",
    "    cap = cv2.VideoCapture('test1.mp4')\n",
    "\n",
    "    fps_start_time = datetime.datetime.now()\n",
    "    fps = 0\n",
    "    total_frames = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        frame = imutils.resize(frame, width=600)\n",
    "        total_frames = total_frames + 1\n",
    "\n",
    "        (H, W) = frame.shape[:2]\n",
    "\n",
    "        blob = cv2.dnn.blobFromImage(frame, 0.007843, (W, H), 127.5)\n",
    "\n",
    "        detector.setInput(blob)\n",
    "        person_detections = detector.forward()\n",
    "        \n",
    "\n",
    "        for i in np.arange(0, person_detections.shape[2]):\n",
    "            confidence = person_detections[0, 0, i, 2]\n",
    "            if confidence > 0.5:\n",
    "                idx = int(person_detections[0, 0, i, 1])\n",
    "\n",
    "                if CLASSES[idx] != \"person\":\n",
    "                    continue\n",
    "\n",
    "                person_box = person_detections[0, 0, i, 3:7] * np.array([W, H, W, H])\n",
    "                (startX, startY, endX, endY) = person_box.astype(\"int\")\n",
    "                area = frame[startY:endY, startX:endX]\n",
    "                cv2.imshow(\"Application\", area)\n",
    "                cv2.imwrite(\"C:\\\\Users\\\\elhab\\\\Documents\\\\IoMT\\\\Face_recognition\\\\imgs\\\\Application{:>1}.jpg\".format(total_frames), area)\n",
    "                cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 0, 255), 2)\n",
    "        \n",
    "        \n",
    "\n",
    "        fps_end_time = datetime.datetime.now()\n",
    "        time_diff = fps_end_time - fps_start_time\n",
    "        if time_diff.seconds == 0:\n",
    "            fps = 0.0\n",
    "        else:\n",
    "            fps = (total_frames / time_diff.seconds)\n",
    "\n",
    "        fps_text = \"FPS: {:.2f}\".format(fps)\n",
    "\n",
    "        cv2.putText(frame, fps_text, (5, 30), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 0, 255), 1)\n",
    "\n",
    "        \n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4a0b8e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import os\n",
    "from datetime import datetime\n",
    "import datetime\n",
    "import time\n",
    "import boto3\n",
    "import ssl\n",
    "import imutils\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d5767311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hachami.jpg', 'Hafida.jpg', 'ibtihal.jpg', 'Salma.jpg']\n",
      "[array([[[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]],\n",
      "\n",
      "       [[1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]],\n",
      "\n",
      "       [[1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]]], dtype=uint8), array([[[ 11, 106, 126],\n",
      "        [ 20, 106, 128],\n",
      "        [ 74, 147, 169],\n",
      "        ...,\n",
      "        [ 33,  36,  34],\n",
      "        [ 27,  30,  28],\n",
      "        [ 29,  32,  30]],\n",
      "\n",
      "       [[ 25, 119, 138],\n",
      "        [ 35, 121, 141],\n",
      "        [ 37, 110, 130],\n",
      "        ...,\n",
      "        [ 41,  44,  42],\n",
      "        [ 30,  33,  31],\n",
      "        [ 22,  25,  23]],\n",
      "\n",
      "       [[ 35, 121, 141],\n",
      "        [ 32, 114, 132],\n",
      "        [ 61, 130, 150],\n",
      "        ...,\n",
      "        [ 30,  33,  31],\n",
      "        [ 31,  34,  32],\n",
      "        [ 31,  34,  32]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  3,   3,   3],\n",
      "        [  2,   2,   2],\n",
      "        [  2,   2,   2],\n",
      "        ...,\n",
      "        [ 81,  95, 101],\n",
      "        [ 78,  92,  98],\n",
      "        [ 76,  90,  96]],\n",
      "\n",
      "       [[  1,   1,   1],\n",
      "        [  0,   0,   0],\n",
      "        [  4,   4,   4],\n",
      "        ...,\n",
      "        [ 80,  94, 100],\n",
      "        [ 76,  90,  96],\n",
      "        [ 79,  93,  99]],\n",
      "\n",
      "       [[  5,   5,   5],\n",
      "        [  3,   3,   3],\n",
      "        [  4,   4,   4],\n",
      "        ...,\n",
      "        [ 77,  91,  97],\n",
      "        [ 82,  96, 102],\n",
      "        [ 75,  89,  95]]], dtype=uint8), array([[[192, 178, 155],\n",
      "        [188, 174, 151],\n",
      "        [186, 172, 150],\n",
      "        ...,\n",
      "        [225, 194, 161],\n",
      "        [219, 191, 156],\n",
      "        [190, 161, 122]],\n",
      "\n",
      "       [[208, 194, 172],\n",
      "        [205, 191, 169],\n",
      "        [195, 181, 159],\n",
      "        ...,\n",
      "        [211, 181, 146],\n",
      "        [191, 163, 128],\n",
      "        [168, 142, 102]],\n",
      "\n",
      "       [[191, 177, 158],\n",
      "        [184, 170, 151],\n",
      "        [179, 165, 146],\n",
      "        ...,\n",
      "        [193, 164, 125],\n",
      "        [181, 154, 117],\n",
      "        [200, 175, 135]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 10,   9,  18],\n",
      "        [ 11,  10,  19],\n",
      "        [ 11,  11,  17],\n",
      "        ...,\n",
      "        [ 17,  28,  42],\n",
      "        [ 17,  28,  42],\n",
      "        [ 16,  27,  41]],\n",
      "\n",
      "       [[ 10,   9,  18],\n",
      "        [ 10,   9,  18],\n",
      "        [ 11,  11,  17],\n",
      "        ...,\n",
      "        [ 18,  29,  43],\n",
      "        [ 18,  29,  43],\n",
      "        [ 18,  29,  43]],\n",
      "\n",
      "       [[  9,   8,  17],\n",
      "        [ 10,   9,  18],\n",
      "        [ 11,  11,  17],\n",
      "        ...,\n",
      "        [ 19,  30,  44],\n",
      "        [ 19,  30,  44],\n",
      "        [ 22,  33,  47]]], dtype=uint8), array([[[180, 171, 157],\n",
      "        [196, 187, 173],\n",
      "        [209, 200, 187],\n",
      "        ...,\n",
      "        [213, 182, 157],\n",
      "        [212, 180, 157],\n",
      "        [215, 184, 159]],\n",
      "\n",
      "       [[172, 163, 149],\n",
      "        [192, 183, 169],\n",
      "        [210, 201, 188],\n",
      "        ...,\n",
      "        [248, 218, 191],\n",
      "        [248, 218, 191],\n",
      "        [244, 213, 188]],\n",
      "\n",
      "       [[181, 172, 158],\n",
      "        [204, 195, 181],\n",
      "        [221, 212, 199],\n",
      "        ...,\n",
      "        [227, 199, 165],\n",
      "        [224, 195, 164],\n",
      "        [229, 199, 170]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 49,  74, 118],\n",
      "        [ 54,  79, 123],\n",
      "        [ 59,  84, 128],\n",
      "        ...,\n",
      "        [ 89, 127, 169],\n",
      "        [ 90, 128, 170],\n",
      "        [ 90, 128, 170]],\n",
      "\n",
      "       [[ 55,  80, 124],\n",
      "        [ 58,  83, 127],\n",
      "        [ 63,  88, 132],\n",
      "        ...,\n",
      "        [ 87, 125, 167],\n",
      "        [ 87, 125, 167],\n",
      "        [ 88, 126, 168]],\n",
      "\n",
      "       [[ 62,  87, 131],\n",
      "        [ 61,  86, 130],\n",
      "        [ 67,  92, 136],\n",
      "        ...,\n",
      "        [ 87, 125, 167],\n",
      "        [ 86, 124, 166],\n",
      "        [ 86, 124, 166]]], dtype=uint8)]\n"
     ]
    }
   ],
   "source": [
    "path = 'C:\\\\Users\\\\elhab\\\\Documents\\\\IoMT\\\\Face_recognition\\\\images'\n",
    "images = []\n",
    "names=[\"Hachami\",\"Hafida\",\"ibtihal\",\"Salma\"]\n",
    "myList = os.listdir(path)\n",
    "print(myList)\n",
    "\n",
    "for cl in myList:\n",
    "    curImg = cv2.imread(f'{path}/{cl}')\n",
    "    images.append(curImg)\n",
    "print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "06eb03f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding Complete\n"
     ]
    }
   ],
   "source": [
    "def findEncodings(images):\n",
    "    encodeList = []\n",
    "\n",
    "\n",
    "    for img in images:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        encode = face_recognition.face_encodings(img)[0]\n",
    "        encodeList.append(encode)\n",
    "    return encodeList\n",
    "encodeListKnown = findEncodings(images)\n",
    "print('Encoding Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b7ab9ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ibtihal', 'Salma', 'Hafida']\n"
     ]
    }
   ],
   "source": [
    "list=[]\n",
    "folderdir=\"C:\\\\Users\\\\elhab\\\\Documents\\\\IoMT\\\\Face_recognition\\\\imgs\"\n",
    "my_List = os.listdir(folderdir)\n",
    "for cl in my_List:\n",
    "    img= cv2.imread(f'{folderdir}/{cl}')\n",
    "    imgS = cv2.resize(img, (0, 0), None, 0.25, 0.25)\n",
    "    imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n",
    "    facesCurFrame = face_recognition.face_locations(imgS)\n",
    "    encodesCurFrame = face_recognition.face_encodings(imgS, facesCurFrame)\n",
    "    for encodeFace, faceLoc in zip(encodesCurFrame, facesCurFrame):\n",
    "        matches = face_recognition.compare_faces(encodeListKnown, encodeFace)\n",
    "        faceDis = face_recognition.face_distance(encodeListKnown, encodeFace)\n",
    "    matchIndex = np.argmin(faceDis)\n",
    "    if (matches[matchIndex]) & (names[matchIndex] not in list):\n",
    "        list.append(names[matchIndex])\n",
    "        \n",
    "print(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68ff120",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
